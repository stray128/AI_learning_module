{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA Integration - Part 2: Full EDA Workflow\n",
    "\n",
    "This notebook covers complete exploratory data analysis combining all skills.\n",
    "\n",
    "**Topics covered:**\n",
    "- Data loading and inspection\n",
    "- Missing data analysis\n",
    "- Statistical summaries\n",
    "- Visualization for EDA\n",
    "- Feature engineering basics\n",
    "\n",
    "**Problems:** 20 (Easy: 1-7, Medium: 8-14, Hard: 15-20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================\n# SETUP - Run this cell first!\n# ============================================\nimport sys\nsys.path.insert(0, '..')\nfrom utils.checks import eda_02_full_eda_workflow as verify\n\n# Dataset paths (provided for convenience)\nTITANIC_PATH = '../datasets/public/titanic.csv'\nTIPS_PATH = '../datasets/public/tips.csv'\n\nprint(\"Verification module loaded! Dataset paths defined.\")\nprint(f\"Titanic: {TITANIC_PATH}\")\nprint(f\"Tips: {TIPS_PATH}\")\nprint(\"\\nNow import the libraries you need and load the datasets.\")"
  },
  {
   "cell_type": "markdown",
   "source": "---\n## Problem 0: Import Libraries and Load Data\n**Difficulty:** Easy\n\n### Concept\nA complete EDA workflow requires importing data analysis and visualization libraries, then loading your datasets.\n\n### Syntax\n```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n%matplotlib inline\n\n# Load datasets\ntitanic = pd.read_csv(TITANIC_PATH)\ntips = pd.read_csv(TIPS_PATH)\n```\n\n### Task\n1. Import NumPy as `np`, Pandas as `pd`, and matplotlib.pyplot as `plt`\n2. Enable inline plotting with `%matplotlib inline`\n3. Load the Titanic and Tips datasets using the paths provided in SETUP\n\n### Expected Properties\n- All libraries should be imported\n- `titanic` and `tips` should be DataFrames",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Your solution:\n",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Verification\nverify.p0(globals())",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Problem 1: Get Dataset Shape\n",
    "**Difficulty:** Easy\n",
    "\n",
    "### Concept\n",
    "The first step in any EDA is understanding the size of your dataset. The `.shape` attribute returns a tuple of (rows, columns), giving you an immediate sense of the data scale.\n",
    "\n",
    "### Syntax\n",
    "```python\n",
    "# Get shape of DataFrame\n",
    "shape = df.shape  # Returns (rows, columns)\n",
    "```\n",
    "\n",
    "### Example\n",
    "```python\n",
    ">>> df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})\n",
    ">>> df.shape\n",
    "(3, 2)  # 3 rows, 2 columns\n",
    "```\n",
    "\n",
    "### Task\n",
    "Get the shape of the Titanic dataset. Store it in `shape`.\n",
    "\n",
    "### Expected Properties\n",
    "- `shape` should be a tuple\n",
    "- Should have 2 elements (rows, columns)\n",
    "- Number of rows should be greater than 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution:\n",
    "shape = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Verification\nverify.p1(shape)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Problem 2: Get Data Types\n",
    "**Difficulty:** Easy\n",
    "\n",
    "### Concept\n",
    "Understanding the data types of each column helps you know what operations are valid and whether data needs type conversion. The `.dtypes` attribute returns a Series with column names as index and data types as values.\n",
    "\n",
    "### Syntax\n",
    "```python\n",
    "# Get data types of all columns\n",
    "dtypes = df.dtypes\n",
    "```\n",
    "\n",
    "### Example\n",
    "```python\n",
    ">>> df = pd.DataFrame({'A': [1, 2], 'B': ['x', 'y']})\n",
    ">>> df.dtypes\n",
    "A     int64\n",
    "B    object\n",
    "dtype: object\n",
    "```\n",
    "\n",
    "### Task\n",
    "Get the data types for all columns in the Titanic dataset. Store the result in `dtypes`.\n",
    "\n",
    "### Expected Properties\n",
    "- `dtypes` should be a pandas Series\n",
    "- Should have an entry for each column in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution:\n",
    "dtypes = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Verification\nverify.p2(dtypes)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Problem 3: Preview First Rows\n",
    "**Difficulty:** Easy\n",
    "\n",
    "### Concept\n",
    "Looking at the first few rows gives you a quick sense of the data structure and sample values. The `.head()` method is one of the most commonly used methods in EDA.\n",
    "\n",
    "### Syntax\n",
    "```python\n",
    "# Get first n rows (default is 5)\n",
    "first_rows = df.head(n)\n",
    "\n",
    "# Get last n rows\n",
    "last_rows = df.tail(n)\n",
    "```\n",
    "\n",
    "### Example\n",
    "```python\n",
    ">>> df = pd.DataFrame({'A': range(10)})\n",
    ">>> df.head(3)\n",
    "   A\n",
    "0  0\n",
    "1  1\n",
    "2  2\n",
    "```\n",
    "\n",
    "### Task\n",
    "Get the first 3 rows and last 3 rows of the Titanic dataset. Store them in `first_rows` and `last_rows`.\n",
    "\n",
    "### Expected Properties\n",
    "- Both should be DataFrames\n",
    "- Each should have exactly 3 rows\n",
    "- Should have the same number of columns as the original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution:\n",
    "first_rows = None\n",
    "last_rows = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Verification\nverify.p3(first_rows, last_rows, titanic)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Problem 4: Count Missing Values\n",
    "**Difficulty:** Easy\n",
    "\n",
    "### Concept\n",
    "Missing data is common in real-world datasets. Identifying how much data is missing helps you decide on appropriate handling strategies (imputation, deletion, etc.).\n",
    "\n",
    "### Syntax\n",
    "```python\n",
    "# Count missing values per column\n",
    "missing_counts = df.isnull().sum()\n",
    "\n",
    "# OR\n",
    "missing_counts = df.isna().sum()\n",
    "```\n",
    "\n",
    "### Example\n",
    "```python\n",
    ">>> df = pd.DataFrame({'A': [1, None, 3], 'B': [4, 5, None]})\n",
    ">>> df.isnull().sum()\n",
    "A    1\n",
    "B    1\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "### Task\n",
    "Count the number of missing values in each column of the Titanic dataset. Store the result in `missing_counts`.\n",
    "\n",
    "### Expected Properties\n",
    "- `missing_counts` should be a pandas Series\n",
    "- Should have non-negative integer values\n",
    "- Should have an entry for each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution:\n",
    "missing_counts = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Verification\nverify.p4(missing_counts, titanic)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Problem 5: Calculate Missing Percentage\n",
    "**Difficulty:** Easy\n",
    "\n",
    "### Concept\n",
    "While counts are useful, percentages give you a better sense of the proportion of missing data relative to the total dataset size. This helps prioritize which missing data to address first.\n",
    "\n",
    "### Syntax\n",
    "```python\n",
    "# Calculate missing percentage\n",
    "missing_pct = (df.isnull().sum() / len(df)) * 100\n",
    "```\n",
    "\n",
    "### Example\n",
    "```python\n",
    ">>> df = pd.DataFrame({'A': [1, None, 3, 4]})\n",
    ">>> (df.isnull().sum() / len(df)) * 100\n",
    "A    25.0\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "### Task\n",
    "Calculate the percentage of missing values for each column in the Titanic dataset. Store the result in `missing_pct`.\n",
    "\n",
    "### Expected Properties\n",
    "- `missing_pct` should be a pandas Series\n",
    "- All values should be between 0 and 100\n",
    "- Should be numeric (float) values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution:\n",
    "missing_pct = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Verification\nverify.p5(missing_pct, titanic)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Problem 6: Get Descriptive Statistics\n",
    "**Difficulty:** Easy\n",
    "\n",
    "### Concept\n",
    "Descriptive statistics (mean, std, min, max, quartiles) provide a statistical summary of numerical columns. This is crucial for understanding the distribution and range of your data.\n",
    "\n",
    "### Syntax\n",
    "```python\n",
    "# Get descriptive statistics for numerical columns\n",
    "desc_stats = df.describe()\n",
    "```\n",
    "\n",
    "### Example\n",
    "```python\n",
    ">>> df = pd.DataFrame({'A': [1, 2, 3, 4, 5]})\n",
    ">>> df.describe()\n",
    "              A\n",
    "count  5.000000\n",
    "mean   3.000000\n",
    "std    1.581139\n",
    "min    1.000000\n",
    "25%    2.000000\n",
    "50%    3.000000\n",
    "75%    4.000000\n",
    "max    5.000000\n",
    "```\n",
    "\n",
    "### Task\n",
    "Get descriptive statistics for the Titanic dataset. Store the result in `desc_stats`.\n",
    "\n",
    "### Expected Properties\n",
    "- `desc_stats` should be a DataFrame\n",
    "- Should include statistics like 'mean', 'std', 'min', 'max'\n",
    "- Should only include numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution:\n",
    "desc_stats = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Verification\nverify.p6(desc_stats)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Problem 7: Value Counts for Categorical Column\n",
    "**Difficulty:** Easy\n",
    "\n",
    "### Concept\n",
    "For categorical data, value counts show the frequency distribution of each category. This is essential for understanding the distribution of categorical variables.\n",
    "\n",
    "### Syntax\n",
    "```python\n",
    "# Get value counts for a column\n",
    "counts = df['column'].value_counts()\n",
    "```\n",
    "\n",
    "### Example\n",
    "```python\n",
    ">>> df = pd.DataFrame({'day': ['Mon', 'Tue', 'Mon', 'Wed', 'Mon']})\n",
    ">>> df['day'].value_counts()\n",
    "Mon    3\n",
    "Tue    1\n",
    "Wed    1\n",
    "Name: day, dtype: int64\n",
    "```\n",
    "\n",
    "### Task\n",
    "Get value counts for the 'day' column in the Tips dataset. Store the result in `day_counts`.\n",
    "\n",
    "### Expected Properties\n",
    "- `day_counts` should be a pandas Series\n",
    "- Should have positive integer values\n",
    "- Should have at least one entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution:\n",
    "day_counts = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Verification\nverify.p7(day_counts)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Problem 8: Count Unique Values\n",
    "**Difficulty:** Medium\n",
    "\n",
    "### Concept\n",
    "Knowing the number of unique values in a column helps determine if it's truly categorical (few unique values) or continuous (many unique values). The `nunique()` method counts distinct values.\n",
    "\n",
    "### Syntax\n",
    "```python\n",
    "# Get unique values\n",
    "unique_vals = df['column'].unique()\n",
    "\n",
    "# Count unique values\n",
    "n_unique = df['column'].nunique()\n",
    "```\n",
    "\n",
    "### Example\n",
    "```python\n",
    ">>> df = pd.DataFrame({'sex': ['M', 'F', 'M', 'F']})\n",
    ">>> df['sex'].unique()\n",
    "array(['M', 'F'], dtype=object)\n",
    ">>> df['sex'].nunique()\n",
    "2\n",
    "```\n",
    "\n",
    "### Task\n",
    "For the 'sex' column in the Tips dataset, get the unique values and count of unique values. Store them in `unique_vals` and `n_unique`.\n",
    "\n",
    "### Expected Properties\n",
    "- `unique_vals` should be a NumPy array\n",
    "- `n_unique` should be an integer\n",
    "- `n_unique` should equal the length of `unique_vals`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution:\n",
    "unique_vals = None\n",
    "n_unique = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Verification\nverify.p8(unique_vals, n_unique)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Problem 9: Create Histogram\n",
    "**Difficulty:** Medium\n",
    "\n",
    "### Concept\n",
    "Histograms visualize the distribution of numerical data by showing the frequency of values within bins. They're essential for identifying skewness, outliers, and the overall data distribution shape.\n",
    "\n",
    "### Syntax\n",
    "```python\n",
    "# Create histogram\n",
    "fig, ax = plt.subplots()\n",
    "n, bins, patches = ax.hist(df['column'], bins=20)\n",
    "ax.set_xlabel('Label')\n",
    "ax.set_ylabel('Frequency')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "### Example\n",
    "```python\n",
    ">>> fig, ax = plt.subplots()\n",
    ">>> ax.hist([1, 2, 2, 3, 3, 3, 4], bins=4)\n",
    ">>> plt.show()\n",
    "```\n",
    "\n",
    "### Task\n",
    "Create a histogram of the 'total_bill' column in the Tips dataset. Store the histogram return values (n, bins, patches) in variables with those names.\n",
    "\n",
    "### Expected Properties\n",
    "- Should create a matplotlib figure\n",
    "- `n`, `bins`, and `patches` should be returned from ax.hist()\n",
    "- `n` should be an array of frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution:\n",
    "fig, ax = plt.subplots()\n",
    "# Create histogram of total_bill\n",
    "n, bins, patches = None, None, None\n",
    "\n",
    "ax.set_xlabel('Total Bill')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_title('Distribution of Total Bill')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Verification\nverify.p9(n, bins, patches)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Problem 10: Create Box Plot by Category\n",
    "**Difficulty:** Medium\n",
    "\n",
    "### Concept\n",
    "Box plots show the distribution of data through quartiles and help identify outliers. When grouped by category, they allow comparison of distributions across different groups.\n",
    "\n",
    "### Syntax\n",
    "```python\n",
    "# Box plot grouped by category\n",
    "df.boxplot(column='value_col', by='category_col')\n",
    "\n",
    "# OR using groupby\n",
    "df.groupby('category')['value'].plot(kind='box')\n",
    "```\n",
    "\n",
    "### Example\n",
    "```python\n",
    ">>> df = pd.DataFrame({\n",
    "...     'group': ['A', 'A', 'B', 'B'],\n",
    "...     'value': [1, 2, 3, 4]\n",
    "... })\n",
    ">>> df.boxplot(column='value', by='group')\n",
    "```\n",
    "\n",
    "### Task\n",
    "Create box plots showing 'total_bill' grouped by 'day' in the Tips dataset. Store the result in `bp`.\n",
    "\n",
    "### Expected Properties\n",
    "- Should create a visualization\n",
    "- `bp` should be the return value from the boxplot function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution:\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "bp = None  # Create box plots (hint: use tips.boxplot())\n",
    "\n",
    "plt.suptitle('')  # Remove default title\n",
    "ax.set_title('Total Bill by Day')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Verification\nverify.p10(bp)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Problem 11: Create Scatter Plot with Groups\n",
    "**Difficulty:** Medium\n",
    "\n",
    "### Concept\n",
    "Scatter plots reveal relationships between two numerical variables. Coloring points by a categorical variable adds a third dimension to the analysis, showing how relationships differ across groups.\n",
    "\n",
    "### Syntax\n",
    "```python\n",
    "# Scatter plot with different colors for groups\n",
    "fig, ax = plt.subplots()\n",
    "for group in df['category'].unique():\n",
    "    subset = df[df['category'] == group]\n",
    "    ax.scatter(subset['x'], subset['y'], label=group)\n",
    "ax.legend()\n",
    "```\n",
    "\n",
    "### Example\n",
    "```python\n",
    ">>> fig, ax = plt.subplots()\n",
    ">>> males = df[df['sex'] == 'Male']\n",
    ">>> females = df[df['sex'] == 'Female']\n",
    ">>> ax.scatter(males['x'], males['y'], label='Male')\n",
    ">>> ax.scatter(females['x'], females['y'], label='Female')\n",
    ">>> ax.legend()\n",
    "```\n",
    "\n",
    "### Task\n",
    "Create a scatter plot of 'total_bill' vs 'tip', with different colors for 'Male' and 'Female'. Store the scatter plot return values in `scatter1` and `scatter2`.\n",
    "\n",
    "### Expected Properties\n",
    "- Should create two scatter plots (one for each sex)\n",
    "- Both scatter objects should be returned\n",
    "- Plot should have a legend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution:\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "male = tips[tips['sex'] == 'Male']\n",
    "female = tips[tips['sex'] == 'Female']\n",
    "\n",
    "scatter1 = None  # Plot male\n",
    "scatter2 = None  # Plot female\n",
    "\n",
    "ax.set_xlabel('Total Bill')\n",
    "ax.set_ylabel('Tip')\n",
    "ax.set_title('Total Bill vs Tip by Sex')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Verification\nverify.p11(scatter1, scatter2)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Problem 12: Group Statistics\n",
    "**Difficulty:** Medium\n",
    "\n",
    "### Concept\n",
    "Grouping data and calculating statistics reveals patterns across categories. This is fundamental to comparative analysis and understanding how variables differ between groups.\n",
    "\n",
    "### Syntax\n",
    "```python\n",
    "# Group by one or more columns and calculate statistics\n",
    "grouped = df.groupby(['col1', 'col2'])['value_col'].mean()\n",
    "\n",
    "# Multiple aggregations\n",
    "grouped = df.groupby('col')['value'].agg(['mean', 'std', 'count'])\n",
    "```\n",
    "\n",
    "### Example\n",
    "```python\n",
    ">>> df = pd.DataFrame({\n",
    "...     'category': ['A', 'A', 'B', 'B'],\n",
    "...     'value': [10, 20, 30, 40]\n",
    "... })\n",
    ">>> df.groupby('category')['value'].mean()\n",
    "category\n",
    "A    15.0\n",
    "B    35.0\n",
    "Name: value, dtype: float64\n",
    "```\n",
    "\n",
    "### Task\n",
    "Calculate the mean tip grouped by both 'day' and 'time' in the Tips dataset. Store the result in `grouped_mean`.\n",
    "\n",
    "### Expected Properties\n",
    "- `grouped_mean` should be a pandas Series\n",
    "- Should have a MultiIndex (day and time)\n",
    "- Values should be numeric (mean tips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution:\n",
    "grouped_mean = None  # Group by ['day', 'time'] and get mean tip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Verification\nverify.p12(grouped_mean)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Problem 13: Create Bar Chart of Aggregated Data\n",
    "**Difficulty:** Medium\n",
    "\n",
    "### Concept\n",
    "Bar charts are ideal for comparing values across categories. They make it easy to see which categories have higher or lower values at a glance.\n",
    "\n",
    "### Syntax\n",
    "```python\n",
    "# Create bar chart from aggregated data\n",
    "grouped_data = df.groupby('category')['value'].mean()\n",
    "fig, ax = plt.subplots()\n",
    "bars = ax.bar(grouped_data.index, grouped_data.values)\n",
    "```\n",
    "\n",
    "### Example\n",
    "```python\n",
    ">>> data = pd.Series([10, 20, 15], index=['A', 'B', 'C'])\n",
    ">>> fig, ax = plt.subplots()\n",
    ">>> ax.bar(data.index, data.values)\n",
    "```\n",
    "\n",
    "### Task\n",
    "Create a bar chart showing the average tip by day. Store the bar chart return value in `bars`.\n",
    "\n",
    "### Expected Properties\n",
    "- Should create a bar chart\n",
    "- `bars` should be the return value from ax.bar()\n",
    "- Chart should show one bar per day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution:\n",
    "avg_tip_by_day = tips.groupby('day')['tip'].mean()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "bars = None  # Create bar chart\n",
    "\n",
    "ax.set_ylabel('Average Tip')\n",
    "ax.set_xlabel('Day')\n",
    "ax.set_title('Average Tip by Day')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Verification\nverify.p13(bars)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Problem 14: Create Pie Chart\n",
    "**Difficulty:** Medium\n",
    "\n",
    "### Concept\n",
    "Pie charts show proportions of a whole, making them useful for displaying the composition of categorical data. They work best with a small number of categories.\n",
    "\n",
    "### Syntax\n",
    "```python\n",
    "# Create pie chart\n",
    "counts = df['category'].value_counts()\n",
    "fig, ax = plt.subplots()\n",
    "wedges, texts, autotexts = ax.pie(counts, labels=counts.index, autopct='%1.1f%%')\n",
    "```\n",
    "\n",
    "### Example\n",
    "```python\n",
    ">>> data = pd.Series([30, 70], index=['A', 'B'])\n",
    ">>> fig, ax = plt.subplots()\n",
    ">>> ax.pie(data, labels=data.index, autopct='%1.1f%%')\n",
    "```\n",
    "\n",
    "### Task\n",
    "Create a pie chart showing the distribution of smokers vs non-smokers in the Tips dataset. Store the wedges in `wedges`.\n",
    "\n",
    "### Expected Properties\n",
    "- Should create a pie chart\n",
    "- `wedges` should contain the pie wedge objects\n",
    "- Should show percentages for each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution:\n",
    "smoker_counts = tips['smoker'].value_counts()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "wedges, texts, autotexts = None, None, None  # Create pie chart\n",
    "\n",
    "ax.set_title('Smoker Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Verification\nverify.p14(wedges)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Problem 15: Create Derived Feature\n",
    "**Difficulty:** Hard\n",
    "\n",
    "### Concept\n",
    "Feature engineering creates new variables from existing ones to reveal patterns or prepare data for modeling. Derived features often provide more insight than raw values.\n",
    "\n",
    "### Syntax\n",
    "```python\n",
    "# Create derived feature\n",
    "df['new_feature'] = df['col1'] / df['col2']\n",
    "df['percentage'] = (df['part'] / df['total']) * 100\n",
    "```\n",
    "\n",
    "### Example\n",
    "```python\n",
    ">>> df = pd.DataFrame({'sales': [100, 200], 'cost': [80, 150]})\n",
    ">>> df['profit_margin'] = ((df['sales'] - df['cost']) / df['sales']) * 100\n",
    ">>> df\n",
    "   sales  cost  profit_margin\n",
    "0    100    80           20.0\n",
    "1    200   150           25.0\n",
    "```\n",
    "\n",
    "### Task\n",
    "Create a new column 'tip_percentage' that calculates (tip / total_bill) * 100. Store the modified DataFrame in `tips_with_pct`.\n",
    "\n",
    "### Expected Properties\n",
    "- DataFrame should have a 'tip_percentage' column\n",
    "- Values should be between 0 and 100\n",
    "- Mean tip percentage should be between 10 and 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution:\n",
    "tips_with_pct = tips.copy()\n",
    "tips_with_pct['tip_percentage'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Verification\nverify.p15(tips_with_pct)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Problem 16: Create Multi-Panel Figure\n",
    "**Difficulty:** Hard\n",
    "\n",
    "### Concept\n",
    "Multi-panel figures allow you to display multiple related visualizations side-by-side, providing a comprehensive view of the data. This is essential for creating effective EDA reports.\n",
    "\n",
    "### Syntax\n",
    "```python\n",
    "# Create subplots grid\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(12, 10))\n",
    "\n",
    "# Access individual subplots\n",
    "axes[0, 0].plot(...)  # Top-left\n",
    "axes[0, 1].plot(...)  # Top-right\n",
    "axes[1, 0].plot(...)  # Bottom-left\n",
    "axes[1, 1].plot(...)  # Bottom-right\n",
    "\n",
    "plt.tight_layout()\n",
    "```\n",
    "\n",
    "### Example\n",
    "```python\n",
    ">>> fig, axes = plt.subplots(2, 2, figsize=(10, 8))\n",
    ">>> axes[0, 0].hist(data['col1'])\n",
    ">>> axes[0, 1].scatter(data['x'], data['y'])\n",
    ">>> plt.tight_layout()\n",
    "```\n",
    "\n",
    "### Task\n",
    "Create a 2x2 subplot figure showing:\n",
    "- Top-left: Histogram of 'total_bill'\n",
    "- Top-right: Histogram of 'tip'\n",
    "- Bottom-left: Scatter plot of 'total_bill' vs 'tip'\n",
    "- Bottom-right: Bar chart of count by 'day'\n",
    "\n",
    "### Expected Properties\n",
    "- `axes` should be a 2D array with shape (2, 2)\n",
    "- All four subplots should be created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution:\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# Top-left: Histogram of total_bill\n",
    "# axes[0, 0].hist(...)\n",
    "\n",
    "# Top-right: Histogram of tip\n",
    "# axes[0, 1].hist(...)\n",
    "\n",
    "# Bottom-left: Scatter of total_bill vs tip\n",
    "# axes[1, 0].scatter(...)\n",
    "\n",
    "# Bottom-right: Bar chart of count by day\n",
    "# day_counts = tips['day'].value_counts()\n",
    "# axes[1, 1].bar(...)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Verification\nverify.p16(axes)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Problem 17: Multi-Group Summary Statistics\n",
    "**Difficulty:** Hard\n",
    "\n",
    "### Concept\n",
    "Calculating multiple statistics across groups provides a comprehensive understanding of how data varies. The `agg()` method allows you to compute multiple aggregations simultaneously.\n",
    "\n",
    "### Syntax\n",
    "```python\n",
    "# Multiple statistics with groupby\n",
    "summary = df.groupby(['group1', 'group2'])['value'].agg(['mean', 'std', 'min', 'max'])\n",
    "```\n",
    "\n",
    "### Example\n",
    "```python\n",
    ">>> df = pd.DataFrame({\n",
    "...     'category': ['A', 'A', 'B', 'B'],\n",
    "...     'value': [10, 20, 30, 40]\n",
    "... })\n",
    ">>> df.groupby('category')['value'].agg(['mean', 'std', 'min', 'max'])\n",
    "          mean       std  min  max\n",
    "category                          \n",
    "A         15.0  7.071068   10   20\n",
    "B         35.0  7.071068   30   40\n",
    "```\n",
    "\n",
    "### Task\n",
    "Create a summary table with mean, std, min, and max of 'total_bill' grouped by 'day' and 'time'. Store the result in `summary_table`.\n",
    "\n",
    "### Expected Properties\n",
    "- `summary_table` should be a DataFrame\n",
    "- Should have columns for 'mean', 'std', 'min', 'max'\n",
    "- Should have a MultiIndex from grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution:\n",
    "summary_table = None  # Group by ['day', 'time'] and calculate multiple stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Verification\nverify.p17(summary_table)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Problem 18: Filter and Analyze Subset\n",
    "**Difficulty:** Hard\n",
    "\n",
    "### Concept\n",
    "Filtering creates subsets of data based on conditions, allowing focused analysis of specific segments. Combining multiple filters with boolean operators enables complex selections.\n",
    "\n",
    "### Syntax\n",
    "```python\n",
    "# Filter with multiple conditions\n",
    "filtered = df[(df['col1'] == value1) & (df['col2'] > value2)]\n",
    "\n",
    "# Use isin for multiple values\n",
    "filtered = df[df['col'].isin(['val1', 'val2'])]\n",
    "```\n",
    "\n",
    "### Example\n",
    "```python\n",
    ">>> df = pd.DataFrame({\n",
    "...     'day': ['Mon', 'Tue', 'Sat', 'Sun'],\n",
    "...     'meal': ['Lunch', 'Dinner', 'Dinner', 'Dinner'],\n",
    "...     'bill': [10, 20, 30, 40]\n",
    "... })\n",
    ">>> weekend_dinner = df[(df['day'].isin(['Sat', 'Sun'])) & (df['meal'] == 'Dinner')]\n",
    ">>> weekend_dinner\n",
    "   day    meal  bill\n",
    "2  Sat  Dinner    30\n",
    "3  Sun  Dinner    40\n",
    "```\n",
    "\n",
    "### Task\n",
    "Filter the Tips dataset for dinner on weekends (Sat or Sun). Store the filtered data in `weekend_dinner` and its descriptive statistics in `stats`.\n",
    "\n",
    "### Expected Properties\n",
    "- `weekend_dinner` should be a DataFrame\n",
    "- Should have fewer rows than the original dataset\n",
    "- `stats` should be descriptive statistics of the filtered data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution:\n",
    "weekend_dinner = None  # Filter for (Sat or Sun) AND (Dinner)\n",
    "stats = None  # Get descriptive statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Verification\nverify.p18(weekend_dinner, stats, tips)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Problem 19: Identify High Values\n",
    "**Difficulty:** Hard\n",
    "\n",
    "### Concept\n",
    "Identifying exceptional cases (high/low values, outliers) is crucial in EDA. Boolean masks make it easy to find rows that meet specific criteria.\n",
    "\n",
    "### Syntax\n",
    "```python\n",
    "# Create boolean mask and filter\n",
    "mask = df['column'] > threshold\n",
    "high_values = df[mask]\n",
    "\n",
    "# Or in one line\n",
    "high_values = df[df['column'] > threshold]\n",
    "```\n",
    "\n",
    "### Example\n",
    "```python\n",
    ">>> df = pd.DataFrame({'score': [85, 92, 78, 95, 88]})\n",
    ">>> high_scorers = df[df['score'] > 90]\n",
    ">>> high_scorers\n",
    "   score\n",
    "1     92\n",
    "3     95\n",
    "```\n",
    "\n",
    "### Task\n",
    "Identify all rows where the tip percentage is above 20%. First calculate tip percentage, then filter. Store the result in `high_tippers`.\n",
    "\n",
    "### Expected Properties\n",
    "- `high_tippers` should be a DataFrame\n",
    "- Should only contain rows where tip percentage > 20\n",
    "- Should have at least one row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution:\n",
    "tip_pct = (tips['tip'] / tips['total_bill']) * 100\n",
    "high_tippers = None  # Filter where tip_pct > 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Verification\nverify.p19(high_tippers, tips)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Problem 20: Create EDA Report Function\n",
    "**Difficulty:** Hard\n",
    "\n",
    "### Concept\n",
    "Automating EDA by creating reusable functions saves time and ensures consistency. A good EDA function should provide shape, types, missing data, and basic statistics.\n",
    "\n",
    "### Syntax\n",
    "```python\n",
    "def eda_report(df):\n",
    "    report = {}\n",
    "    report['shape'] = df.shape\n",
    "    report['dtypes'] = df.dtypes\n",
    "    report['missing'] = df.isnull().sum()\n",
    "    report['stats'] = df.describe()\n",
    "    return report\n",
    "```\n",
    "\n",
    "### Example\n",
    "```python\n",
    ">>> def basic_info(df):\n",
    "...     return {\n",
    "...         'rows': len(df),\n",
    "...         'cols': len(df.columns),\n",
    "...         'missing': df.isnull().sum().sum()\n",
    "...     }\n",
    ">>> basic_info(df)\n",
    "{'rows': 100, 'cols': 5, 'missing': 3}\n",
    "```\n",
    "\n",
    "### Task\n",
    "Complete the `basic_eda` function that returns a dictionary with:\n",
    "- 'shape': DataFrame shape\n",
    "- 'columns': List of column names\n",
    "- 'dtypes': Data types\n",
    "- 'missing_counts': Missing value counts\n",
    "- 'missing_pct': Missing value percentages\n",
    "- 'numerical_stats': Descriptive statistics\n",
    "- 'categorical_columns': List of non-numeric columns\n",
    "\n",
    "Test it on the Tips dataset.\n",
    "\n",
    "### Expected Properties\n",
    "- Function should return a dictionary\n",
    "- All dictionary keys should be populated (not None)\n",
    "- Should work on any DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution:\n",
    "def basic_eda(df):\n",
    "    \"\"\"\n",
    "    Generate a basic EDA report for a DataFrame.\n",
    "    Returns a dictionary with various statistics.\n",
    "    \"\"\"\n",
    "    report = {\n",
    "        'shape': None,\n",
    "        'columns': None,\n",
    "        'dtypes': None,\n",
    "        'missing_counts': None,\n",
    "        'missing_pct': None,\n",
    "        'numerical_stats': None,\n",
    "        'categorical_columns': None\n",
    "    }\n",
    "    \n",
    "    # Fill in the report dictionary\n",
    "    # Hint: categorical_columns can be found with df.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "    \n",
    "    return report\n",
    "\n",
    "# Test the function\n",
    "eda_report = basic_eda(tips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Verification\nverify.p20(eda_report)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "Run this cell to see your overall progress on this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}