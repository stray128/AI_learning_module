{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA Integration - Part 1: NumPy and Pandas Combined\n",
    "\n",
    "This notebook covers using NumPy and Pandas together for data analysis.\n",
    "\n",
    "**Topics covered:**\n",
    "- Converting between NumPy and Pandas\n",
    "- Using NumPy functions on DataFrames\n",
    "- Vectorized operations\n",
    "- Custom aggregations\n",
    "\n",
    "**Problems:** 20 (Easy: 1-7, Medium: 8-14, Hard: 15-20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================\n# SETUP - Run this cell first!\n# ============================================\nimport sys\nsys.path.insert(0, '..')\nfrom utils.checks import eda_01_numpy_pandas_combo as verify\n\nprint(\"Verification module loaded! Now import the libraries you need.\")"
  },
  {
   "cell_type": "markdown",
   "source": "---\n## Problem 0: Import Required Libraries\n**Difficulty:** Easy\n\n### Concept\nFor combining NumPy and Pandas operations, you need both libraries imported.\n\n### Syntax\n```python\nimport numpy as np\nimport pandas as pd\n```\n\n### Task\nImport NumPy as `np` and Pandas as `pd`.\n\n### Expected Properties\n- `np` should be the numpy module\n- `pd` should be the pandas module",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Your solution:\n",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Verification\nverify.p0(globals())",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Problem 1: DataFrame to NumPy Array\n",
    "**Difficulty:** Easy\n",
    "\n",
    "### Concept\n",
    "DataFrames and NumPy arrays can be easily converted between each other. Converting to NumPy arrays is useful when you need to use NumPy's extensive mathematical functions or when interfacing with libraries that expect NumPy arrays.\n",
    "\n",
    "### Syntax\n",
    "```python\n",
    "# Convert DataFrame to NumPy array\n",
    "array = df.to_numpy()     # Preferred method\n",
    "# OR\n",
    "array = df.values         # Older method, still works\n",
    "```\n",
    "\n",
    "### Example\n",
    "```python\n",
    ">>> df = pd.DataFrame({'A': [1, 2], 'B': [3, 4]})\n",
    ">>> arr = df.to_numpy()\n",
    ">>> arr\n",
    "array([[1, 3],\n",
    "       [2, 4]])\n",
    ">>> type(arr)\n",
    "<class 'numpy.ndarray'>\n",
    "```\n",
    "\n",
    "### Task\n",
    "Convert the provided DataFrame to a NumPy array using `.to_numpy()` or `.values`. Store the result in `arr`.\n",
    "\n",
    "### Expected Properties\n",
    "- `arr` should be a NumPy ndarray\n",
    "- Shape should be (3, 2) - 3 rows, 2 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution:\n",
    "df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})\n",
    "arr = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Verification\nverify.p1(arr)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Problem 2: NumPy Array to DataFrame\n",
    "**Difficulty:** Easy\n",
    "\n",
    "### Concept\n",
    "Converting NumPy arrays to DataFrames is useful when you want to add labels (column names) to your data or use Pandas' powerful data manipulation features.\n",
    "\n",
    "### Syntax\n",
    "```python\n",
    "# Create DataFrame from array with column names\n",
    "df = pd.DataFrame(array, columns=['col1', 'col2'])\n",
    "```\n",
    "\n",
    "### Example\n",
    "```python\n",
    ">>> arr = np.array([[1, 2], [3, 4]])\n",
    ">>> df = pd.DataFrame(arr, columns=['A', 'B'])\n",
    ">>> df\n",
    "   A  B\n",
    "0  1  2\n",
    "1  3  4\n",
    "```\n",
    "\n",
    "### Task\n",
    "Convert the provided NumPy array to a DataFrame with column names 'X' and 'Y'. Store the result in `df`.\n",
    "\n",
    "### Expected Properties\n",
    "- `df` should be a pandas DataFrame\n",
    "- Should have columns named 'X' and 'Y'\n",
    "- Shape should be (3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution:\n",
    "arr = np.array([[1, 2], [3, 4], [5, 6]])\n",
    "df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Verification\nverify.p2(df)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Problem 3: Apply NumPy Function to Column\n",
    "**Difficulty:** Easy\n",
    "\n",
    "### Concept\n",
    "NumPy functions can be directly applied to pandas Series and DataFrame columns. This is efficient because pandas is built on top of NumPy and uses the same optimized operations.\n",
    "\n",
    "### Syntax\n",
    "```python\n",
    "# Apply NumPy function to Series/column\n",
    "result = np.function_name(df['column'])\n",
    "```\n",
    "\n",
    "### Example\n",
    "```python\n",
    ">>> df = pd.DataFrame({'values': [1, 4, 9]})\n",
    ">>> np.sqrt(df['values'])\n",
    "0    1.0\n",
    "1    2.0\n",
    "2    3.0\n",
    "Name: values, dtype: float64\n",
    "```\n",
    "\n",
    "### Task\n",
    "Apply `np.sqrt()` to the 'values' column of the DataFrame. Store the result in `sqrt_vals`.\n",
    "\n",
    "### Expected Properties\n",
    "- `sqrt_vals` should be a pandas Series\n",
    "- Should have 5 elements\n",
    "- First element should be 1.0, last should be 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution:\n",
    "df = pd.DataFrame({'values': [1, 4, 9, 16, 25]})\n",
    "sqrt_vals = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Verification\nverify.p3(sqrt_vals)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Problem 4: Use np.where with DataFrame\n",
    "**Difficulty:** Easy\n",
    "\n",
    "### Concept\n",
    "`np.where()` is a vectorized conditional operator that's much faster than loops or apply with lambda functions. It's the NumPy equivalent of \"if-else\" for arrays.\n",
    "\n",
    "### Syntax\n",
    "```python\n",
    "# np.where(condition, value_if_true, value_if_false)\n",
    "df['new_col'] = np.where(df['col'] > threshold, 'High', 'Low')\n",
    "```\n",
    "\n",
    "### Example\n",
    "```python\n",
    ">>> df = pd.DataFrame({'score': [45, 75, 60]})\n",
    ">>> df['pass'] = np.where(df['score'] >= 60, 'Pass', 'Fail')\n",
    ">>> df\n",
    "   score  pass\n",
    "0     45  Fail\n",
    "1     75  Pass\n",
    "2     60  Pass\n",
    "```\n",
    "\n",
    "### Task\n",
    "Create a new column 'label' in the DataFrame. If 'value' > 50, label as 'High', else 'Low'. Use `np.where()`.\n",
    "\n",
    "### Expected Properties\n",
    "- DataFrame should have a 'label' column\n",
    "- 'label' column should contain 'High' and 'Low' strings\n",
    "- First element should be 'Low', second should be 'High'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution:\n",
    "df = pd.DataFrame({'value': [30, 60, 40, 80, 20]})\n",
    "# Add 'label' column using np.where\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Verification\nverify.p4(df)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Problem 5: Series to NumPy Array\n",
    "**Difficulty:** Easy\n",
    "\n",
    "### Concept\n",
    "A pandas Series can be converted to a NumPy array, similar to DataFrames. This is useful when you need to pass data to functions that expect arrays or perform NumPy-specific operations.\n",
    "\n",
    "### Syntax\n",
    "```python\n",
    "# Convert Series to array\n",
    "array = series.to_numpy()   # Preferred\n",
    "# OR\n",
    "array = series.values       # Older method\n",
    "```\n",
    "\n",
    "### Example\n",
    "```python\n",
    ">>> s = pd.Series([10, 20, 30])\n",
    ">>> arr = s.to_numpy()\n",
    ">>> arr\n",
    "array([10, 20, 30])\n",
    "```\n",
    "\n",
    "### Task\n",
    "Convert the provided pandas Series to a NumPy array. Store the result in `arr`.\n",
    "\n",
    "### Expected Properties\n",
    "- `arr` should be a NumPy ndarray\n",
    "- Should have 5 elements\n",
    "- First element should be 10, last should be 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution:\n",
    "s = pd.Series([10, 20, 30, 40, 50])\n",
    "arr = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Verification\nverify.p5(arr)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Problem 6: Apply NumPy Broadcasting\n",
    "**Difficulty:** Easy\n",
    "\n",
    "### Concept\n",
    "Broadcasting is a powerful NumPy feature that allows operations between arrays of different shapes. When you add a scalar to a DataFrame, it's broadcast to all elements automatically.\n",
    "\n",
    "### Syntax\n",
    "```python\n",
    "# Add scalar to all elements\n",
    "result = df + scalar\n",
    "\n",
    "# Multiply all elements\n",
    "result = df * scalar\n",
    "```\n",
    "\n",
    "### Example\n",
    "```python\n",
    ">>> df = pd.DataFrame({'A': [1, 2], 'B': [3, 4]})\n",
    ">>> df + 10\n",
    "    A   B\n",
    "0  11  13\n",
    "1  12  14\n",
    "```\n",
    "\n",
    "### Task\n",
    "Add 10 to all values in the DataFrame. Store the result in `df_added`.\n",
    "\n",
    "### Expected Properties\n",
    "- `df_added` should be a DataFrame\n",
    "- Should have same shape as original (3, 2)\n",
    "- Sum of column 'A' should be 36 (11+12+13)\n",
    "- Sum of column 'B' should be 45 (14+15+16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution:\n",
    "df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})\n",
    "df_added = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Verification\nverify.p6(df_added)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Problem 7: Use np.clip on DataFrame\n",
    "**Difficulty:** Easy\n",
    "\n",
    "### Concept\n",
    "`np.clip()` limits values in an array to a specified range. Values below the minimum are set to the minimum, and values above the maximum are set to the maximum. This is useful for outlier handling and data normalization.\n",
    "\n",
    "### Syntax\n",
    "```python\n",
    "# Clip values to range [min_val, max_val]\n",
    "result = np.clip(array, min_val, max_val)\n",
    "```\n",
    "\n",
    "### Example\n",
    "```python\n",
    ">>> arr = np.array([5, 15, 25, 35])\n",
    ">>> np.clip(arr, 10, 30)\n",
    "array([10, 15, 25, 30])  # 5->10, 35->30\n",
    "```\n",
    "\n",
    "### Task\n",
    "Clip the 'values' column to be between 20 and 80 (inclusive). Store the result in `df_clipped` as a DataFrame.\n",
    "\n",
    "### Expected Properties\n",
    "- `df_clipped` should be a DataFrame\n",
    "- Minimum value in 'values' column should be 20\n",
    "- Maximum value in 'values' column should be 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution:\n",
    "df = pd.DataFrame({'values': [10, 30, 50, 70, 90, 100]})\n",
    "df_clipped = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Verification\nverify.p7(df_clipped)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Problem 8: Calculate Z-Scores Using NumPy\n",
    "**Difficulty:** Medium\n",
    "\n",
    "### Concept\n",
    "Z-scores (standard scores) indicate how many standard deviations a value is from the mean. They're used to identify outliers and normalize data. A z-score of 0 means the value equals the mean.\n",
    "\n",
    "### Syntax\n",
    "```python\n",
    "# Z-score formula: (x - mean) / std\n",
    "z_scores = (data - np.mean(data)) / np.std(data)\n",
    "```\n",
    "\n",
    "### Example\n",
    "```python\n",
    ">>> values = np.array([10, 20, 30, 40, 50])\n",
    ">>> z = (values - np.mean(values)) / np.std(values)\n",
    ">>> z\n",
    "array([-1.41, -0.71,  0.  ,  0.71,  1.41])\n",
    "```\n",
    "\n",
    "### Task\n",
    "Calculate z-scores for the 'values' column using the formula (x - mean) / std. Store the result as a pandas Series in `z_scores`.\n",
    "\n",
    "### Expected Properties\n",
    "- `z_scores` should be a pandas Series\n",
    "- Should have 5 elements\n",
    "- Middle value (index 2) should have z-score close to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution:\n",
    "df = pd.DataFrame({'values': [10, 20, 30, 40, 50]})\n",
    "z_scores = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Verification\nverify.p8(z_scores)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Problem 9: Apply Custom NumPy Function\n",
    "**Difficulty:** Medium\n",
    "\n",
    "### Concept\n",
    "Min-Max normalization scales values to a 0-1 range. This is useful for machine learning algorithms that work better with normalized data. The `apply()` method can apply functions to DataFrame columns.\n",
    "\n",
    "### Syntax\n",
    "```python\n",
    "# Min-Max normalization: (x - min) / (max - min)\n",
    "def normalize(x):\n",
    "    return (x - np.min(x)) / (np.max(x) - np.min(x))\n",
    "\n",
    "df_normalized = df.apply(normalize)\n",
    "```\n",
    "\n",
    "### Example\n",
    "```python\n",
    ">>> df = pd.DataFrame({'A': [1, 2, 3, 4, 5]})\n",
    ">>> normalized = (df['A'] - df['A'].min()) / (df['A'].max() - df['A'].min())\n",
    ">>> normalized\n",
    "0    0.00\n",
    "1    0.25\n",
    "2    0.50\n",
    "3    0.75\n",
    "4    1.00\n",
    "```\n",
    "\n",
    "### Task\n",
    "Apply the provided `normalize_col` function to the DataFrame using `.apply()`. Store the result in `df_result`.\n",
    "\n",
    "### Expected Properties\n",
    "- `df_result` should be a DataFrame\n",
    "- Each column's minimum should be 0.0\n",
    "- Each column's maximum should be 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution:\n",
    "df = pd.DataFrame({'A': [1, 2, 3, 4, 5], 'B': [10, 20, 30, 40, 50]})\n",
    "\n",
    "def normalize_col(x):\n",
    "    return (x - np.min(x)) / (np.max(x) - np.min(x))\n",
    "\n",
    "df_result = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Verification\nverify.p9(df_result)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Problem 10: NumPy Random Data in DataFrame\n",
    "**Difficulty:** Medium\n",
    "\n",
    "### Concept\n",
    "NumPy's random module can generate data from various probability distributions. This is useful for creating test data, simulations, and understanding statistical properties.\n",
    "\n",
    "### Syntax\n",
    "```python\n",
    "# Normal distribution (mean=0, std=1)\n",
    "np.random.normal(loc=0, scale=1, size=100)\n",
    "\n",
    "# Uniform distribution [0, 1)\n",
    "np.random.uniform(low=0, high=1, size=100)\n",
    "\n",
    "# Create DataFrame from multiple arrays\n",
    "df = pd.DataFrame({'col1': array1, 'col2': array2})\n",
    "```\n",
    "\n",
    "### Example\n",
    "```python\n",
    ">>> np.random.seed(42)\n",
    ">>> df = pd.DataFrame({\n",
    "...     'normal': np.random.normal(0, 1, 10),\n",
    "...     'uniform': np.random.uniform(0, 1, 10)\n",
    "... })\n",
    "```\n",
    "\n",
    "### Task\n",
    "Create a DataFrame with two columns:\n",
    "- 'normal': 100 samples from standard normal distribution\n",
    "- 'uniform': 100 samples from uniform distribution [0, 1)\n",
    "\n",
    "Store the result in `df_random`.\n",
    "\n",
    "### Expected Properties\n",
    "- `df_random` should be a DataFrame with shape (100, 2)\n",
    "- Should have columns 'normal' and 'uniform'\n",
    "- Uniform column values should be between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution:\n",
    "np.random.seed(42)\n",
    "df_random = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Verification\nverify.p10(df_random)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Problem 11: Correlation Matrix\n",
    "**Difficulty:** Medium\n",
    "\n",
    "### Concept\n",
    "A correlation matrix shows the correlation coefficients between all pairs of variables. Values range from -1 (perfect negative correlation) to +1 (perfect positive correlation). 0 means no linear relationship.\n",
    "\n",
    "### Syntax\n",
    "```python\n",
    "# Calculate correlation matrix\n",
    "corr_matrix = df.corr()\n",
    "```\n",
    "\n",
    "### Example\n",
    "```python\n",
    ">>> df = pd.DataFrame({\n",
    "...     'A': [1, 2, 3, 4],\n",
    "...     'B': [2, 4, 6, 8]  # Perfectly correlated with A\n",
    "... })\n",
    ">>> df.corr()\n",
    "     A    B\n",
    "A  1.0  1.0\n",
    "B  1.0  1.0\n",
    "```\n",
    "\n",
    "### Task\n",
    "Calculate the correlation matrix for the provided DataFrame. Store the result in `corr_matrix`.\n",
    "\n",
    "### Expected Properties\n",
    "- `corr_matrix` should be a DataFrame\n",
    "- Correlation between A and B should be 1.0 (perfect positive)\n",
    "- Correlation between A and C should be -1.0 (perfect negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution:\n",
    "df = pd.DataFrame({\n",
    "    'A': [1, 2, 3, 4, 5],\n",
    "    'B': [2, 4, 6, 8, 10],  # Perfectly correlated with A\n",
    "    'C': [5, 4, 3, 2, 1]    # Negatively correlated with A\n",
    "})\n",
    "\n",
    "corr_matrix = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Verification\nverify.p11(corr_matrix)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Problem 12: Vectorized String Operations\n",
    "**Difficulty:** Medium\n",
    "\n",
    "### Concept\n",
    "Pandas provides vectorized string operations through the `.str` accessor. These operations are much faster than Python loops and make string processing on large datasets efficient.\n",
    "\n",
    "### Syntax\n",
    "```python\n",
    "# Common string operations\n",
    "df['col'].str.lower()      # Convert to lowercase\n",
    "df['col'].str.upper()      # Convert to uppercase\n",
    "df['col'].str.strip()      # Remove whitespace\n",
    "df['col'].str.title()      # Title case\n",
    "\n",
    "# Chain operations\n",
    "df['clean'] = df['col'].str.strip().str.title()\n",
    "```\n",
    "\n",
    "### Example\n",
    "```python\n",
    ">>> df = pd.DataFrame({'name': ['  alice  ', 'BOB']})\n",
    ">>> df['clean'] = df['name'].str.strip().str.title()\n",
    ">>> df\n",
    "        name  clean\n",
    "0   alice    Alice\n",
    "1        BOB    Bob\n",
    "```\n",
    "\n",
    "### Task\n",
    "Clean the 'name' column by:\n",
    "1. Stripping whitespace\n",
    "2. Converting to title case\n",
    "\n",
    "Store the result in a new column `df['name_clean']`.\n",
    "\n",
    "### Expected Properties\n",
    "- DataFrame should have a 'name_clean' column\n",
    "- All names should be in title case (first letter uppercase)\n",
    "- No leading or trailing whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution:\n",
    "df = pd.DataFrame({'name': ['  Alice  ', 'BOB', '  charlie', 'DAVID  ']})\n",
    "# Add 'name_clean' column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Verification\nverify.p12(df)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Problem 13: Use np.select for Multiple Conditions\n",
    "**Difficulty:** Medium\n",
    "\n",
    "### Concept\n",
    "`np.select()` allows you to apply multiple conditions and assign corresponding values. It's like a vectorized \"if-elif-else\" statement, more flexible than `np.where()` which only handles one condition.\n",
    "\n",
    "### Syntax\n",
    "```python\n",
    "conditions = [\n",
    "    df['col'] < 10,\n",
    "    df['col'] < 20,\n",
    "    df['col'] >= 20\n",
    "]\n",
    "choices = ['Low', 'Medium', 'High']\n",
    "df['category'] = np.select(conditions, choices)\n",
    "```\n",
    "\n",
    "### Example\n",
    "```python\n",
    ">>> df = pd.DataFrame({'temp': [5, 15, 25]})\n",
    ">>> conditions = [df['temp'] < 10, df['temp'] < 20, df['temp'] >= 20]\n",
    ">>> choices = ['Cold', 'Cool', 'Warm']\n",
    ">>> df['category'] = np.select(conditions, choices)\n",
    ">>> df\n",
    "   temp category\n",
    "0     5     Cold\n",
    "1    15     Cool\n",
    "2    25     Warm\n",
    "```\n",
    "\n",
    "### Task\n",
    "Create a 'grade' column based on 'score' using `np.select()`:\n",
    "- <60: 'F'\n",
    "- 60-69: 'D'\n",
    "- 70-79: 'C'\n",
    "- 80-89: 'B'\n",
    "- >=90: 'A'\n",
    "\n",
    "The conditions and choices are provided.\n",
    "\n",
    "### Expected Properties\n",
    "- DataFrame should have a 'grade' column\n",
    "- First score (45) should get 'F'\n",
    "- Last score (95) should get 'A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution:\n",
    "df = pd.DataFrame({'score': [45, 65, 75, 85, 95]})\n",
    "\n",
    "conditions = [\n",
    "    df['score'] < 60,\n",
    "    df['score'] < 70,\n",
    "    df['score'] < 80,\n",
    "    df['score'] < 90,\n",
    "    df['score'] >= 90\n",
    "]\n",
    "choices = ['F', 'D', 'C', 'B', 'A']\n",
    "\n",
    "df['grade'] = None  # Use np.select()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Verification\nverify.p13(df)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Problem 14: Rolling Window Calculations\n",
    "**Difficulty:** Medium\n",
    "\n",
    "### Concept\n",
    "Rolling windows (moving averages) smooth out short-term fluctuations and highlight longer-term trends. This is essential for time series analysis and signal processing.\n",
    "\n",
    "### Syntax\n",
    "```python\n",
    "# Calculate rolling mean with window size n\n",
    "rolling_mean = df['col'].rolling(window=n).mean()\n",
    "```\n",
    "\n",
    "### Example\n",
    "```python\n",
    ">>> df = pd.DataFrame({'values': [1, 2, 3, 4, 5]})\n",
    ">>> df['rolling_mean'] = df['values'].rolling(window=3).mean()\n",
    ">>> df\n",
    "   values  rolling_mean\n",
    "0       1           NaN\n",
    "1       2           NaN\n",
    "2       3           2.0  # mean(1,2,3)\n",
    "3       4           3.0  # mean(2,3,4)\n",
    "4       5           4.0  # mean(3,4,5)\n",
    "```\n",
    "\n",
    "### Task\n",
    "Calculate a 3-period rolling mean for the 'values' column. Store the result in `rolling_mean`.\n",
    "\n",
    "### Expected Properties\n",
    "- `rolling_mean` should be a pandas Series\n",
    "- Should have 10 elements\n",
    "- Third element (index 2) should be 2.0 (mean of 1, 2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution:\n",
    "df = pd.DataFrame({'values': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]})\n",
    "rolling_mean = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Verification\nverify.p14(rolling_mean)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Problem 15: Find Outliers with IQR Method\n",
    "**Difficulty:** Hard\n",
    "\n",
    "### Concept\n",
    "The Interquartile Range (IQR) method identifies outliers as values that fall below Q1 - 1.5×IQR or above Q3 + 1.5×IQR, where Q1 is the 25th percentile, Q3 is the 75th percentile, and IQR = Q3 - Q1.\n",
    "\n",
    "### Syntax\n",
    "```python\n",
    "Q1 = df['col'].quantile(0.25)\n",
    "Q3 = df['col'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Outliers are outside [Q1 - 1.5*IQR, Q3 + 1.5*IQR]\n",
    "outliers = (df['col'] < Q1 - 1.5*IQR) | (df['col'] > Q3 + 1.5*IQR)\n",
    "```\n",
    "\n",
    "### Example\n",
    "```python\n",
    ">>> values = [1, 2, 3, 4, 5, 100]  # 100 is an outlier\n",
    ">>> Q1, Q3 = np.percentile(values, [25, 75])\n",
    ">>> IQR = Q3 - Q1\n",
    ">>> outliers = (values < Q1 - 1.5*IQR) | (values > Q3 + 1.5*IQR)\n",
    "```\n",
    "\n",
    "### Task\n",
    "Find outliers in the 'values' column using the IQR method. Store a boolean mask in `is_outlier` (True for outliers).\n",
    "\n",
    "### Expected Properties\n",
    "- `is_outlier` should be a pandas Series of booleans\n",
    "- Should identify exactly 1 outlier\n",
    "- The value 100 should be identified as an outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution:\n",
    "df = pd.DataFrame({'values': [1, 2, 3, 4, 5, 6, 7, 8, 9, 100]})\n",
    "\n",
    "Q1 = df['values'].quantile(0.25)\n",
    "Q3 = df['values'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "is_outlier = None  # Create boolean mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Verification\nverify.p15(is_outlier)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Problem 16: Bin Data with pd.cut\n",
    "**Difficulty:** Hard\n",
    "\n",
    "### Concept\n",
    "Binning (discretization) converts continuous data into categorical bins. This is useful for creating age groups, price ranges, or any categorical groupings from numerical data.\n",
    "\n",
    "### Syntax\n",
    "```python\n",
    "# pd.cut creates bins from continuous data\n",
    "df['category'] = pd.cut(df['col'], \n",
    "                        bins=[0, 18, 65, 100], \n",
    "                        labels=['Young', 'Adult', 'Senior'])\n",
    "```\n",
    "\n",
    "### Example\n",
    "```python\n",
    ">>> df = pd.DataFrame({'age': [5, 25, 70]})\n",
    ">>> df['group'] = pd.cut(df['age'], \n",
    "...                      bins=[0, 18, 65, 100], \n",
    "...                      labels=['Young', 'Adult', 'Senior'])\n",
    ">>> df\n",
    "   age   group\n",
    "0    5   Young\n",
    "1   25   Adult\n",
    "2   70  Senior\n",
    "```\n",
    "\n",
    "### Task\n",
    "Create age groups using `pd.cut()` with the provided bins and labels. Store the result in `df['age_group']`.\n",
    "\n",
    "Bins: 0-18 (Child), 18-35 (Young Adult), 35-55 (Adult), 55+ (Senior)\n",
    "\n",
    "### Expected Properties\n",
    "- DataFrame should have an 'age_group' column\n",
    "- First age (5) should be in 'Child' category\n",
    "- Last age (75) should be in 'Senior' category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution:\n",
    "df = pd.DataFrame({'age': [5, 15, 25, 35, 45, 55, 65, 75]})\n",
    "bins = [0, 18, 35, 55, 100]\n",
    "labels = ['Child', 'Young Adult', 'Adult', 'Senior']\n",
    "\n",
    "df['age_group'] = None  # Use pd.cut()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Verification\nverify.p16(df)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Problem 17: Cumulative Operations\n",
    "**Difficulty:** Hard\n",
    "\n",
    "### Concept\n",
    "Cumulative operations calculate running totals or running maximums. These are useful for tracking cumulative progress, running balances, or maximum values seen so far.\n",
    "\n",
    "### Syntax\n",
    "```python\n",
    "# Cumulative sum - running total\n",
    "df['cumsum'] = df['col'].cumsum()\n",
    "\n",
    "# Cumulative max - highest value so far\n",
    "df['cummax'] = df['col'].cummax()\n",
    "\n",
    "# Also available: cummin(), cumprod()\n",
    "```\n",
    "\n",
    "### Example\n",
    "```python\n",
    ">>> df = pd.DataFrame({'values': [1, 3, 2]})\n",
    ">>> df['cumsum'] = df['values'].cumsum()\n",
    ">>> df['cummax'] = df['values'].cummax()\n",
    ">>> df\n",
    "   values  cumsum  cummax\n",
    "0       1       1       1\n",
    "1       3       4       3\n",
    "2       2       6       3\n",
    "```\n",
    "\n",
    "### Task\n",
    "Calculate cumulative sum and cumulative maximum for the 'values' column. Store them in `df['cumsum']` and `df['cummax']`.\n",
    "\n",
    "### Expected Properties\n",
    "- DataFrame should have 'cumsum' and 'cummax' columns\n",
    "- Last cumsum value should be 28 (sum of all)\n",
    "- Last cummax value should be 10 (maximum value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution:\n",
    "df = pd.DataFrame({'values': [5, 3, 8, 2, 10]})\n",
    "df['cumsum'] = None\n",
    "df['cummax'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Verification\nverify.p17(df)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Problem 18: Rank Data\n",
    "**Difficulty:** Hard\n",
    "\n",
    "### Concept\n",
    "Ranking assigns a rank to each value in a dataset, useful for leaderboards, performance comparisons, and statistical analysis. Lower ranks can represent higher values or vice versa.\n",
    "\n",
    "### Syntax\n",
    "```python\n",
    "# Rank values (default: lowest value gets rank 1)\n",
    "df['rank'] = df['col'].rank()\n",
    "\n",
    "# Rank with highest value getting rank 1\n",
    "df['rank'] = df['col'].rank(ascending=False)\n",
    "```\n",
    "\n",
    "### Example\n",
    "```python\n",
    ">>> df = pd.DataFrame({'score': [85, 90, 78]})\n",
    ">>> df['rank'] = df['score'].rank(ascending=False)\n",
    ">>> df\n",
    "   score  rank\n",
    "0     85   2.0\n",
    "1     90   1.0  # Highest score gets rank 1\n",
    "2     78   3.0\n",
    "```\n",
    "\n",
    "### Task\n",
    "Rank the scores from highest to lowest (highest score gets rank 1). Store the result in `df['rank']`.\n",
    "\n",
    "### Expected Properties\n",
    "- DataFrame should have a 'rank' column\n",
    "- The score 92 should have rank 1.0\n",
    "- All ranks should be positive numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution:\n",
    "df = pd.DataFrame({'score': [85, 90, 78, 92, 88]})\n",
    "df['rank'] = None  # Use rank() with ascending=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Verification\nverify.p18(df)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Problem 19: Percentage Change\n",
    "**Difficulty:** Hard\n",
    "\n",
    "### Concept\n",
    "Percentage change calculates the relative change between consecutive values. This is essential for analyzing growth rates, returns, and trends in time series data.\n",
    "\n",
    "### Syntax\n",
    "```python\n",
    "# Calculate percentage change between consecutive rows\n",
    "df['pct_change'] = df['col'].pct_change()\n",
    "```\n",
    "\n",
    "### Example\n",
    "```python\n",
    ">>> df = pd.DataFrame({'price': [100, 110, 105]})\n",
    ">>> df['pct_change'] = df['price'].pct_change()\n",
    ">>> df\n",
    "   price  pct_change\n",
    "0    100         NaN  # No previous value\n",
    "1    110        0.10  # 10% increase\n",
    "2    105       -0.05  # 5% decrease\n",
    "```\n",
    "\n",
    "### Task\n",
    "Calculate percentage change for the 'price' column. Store the result in `df['pct_change']`.\n",
    "\n",
    "### Expected Properties\n",
    "- DataFrame should have a 'pct_change' column\n",
    "- Second value (index 1) should be approximately 0.10 (10% increase)\n",
    "- First value will be NaN (no previous value to compare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution:\n",
    "df = pd.DataFrame({'price': [100, 110, 105, 120, 115]})\n",
    "df['pct_change'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Verification\nverify.p19(df)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Problem 20: Complex Data Transformation\n",
    "**Difficulty:** Hard\n",
    "\n",
    "### Concept\n",
    "Group-wise calculations allow you to compute statistics within groups and then broadcast those results back to the original DataFrame. This is useful for calculating percentages within categories, standardizing within groups, etc.\n",
    "\n",
    "### Syntax\n",
    "```python\n",
    "# Calculate percentage of group total\n",
    "df['pct_of_group'] = df['value'] / df.groupby('category')['value'].transform('sum')\n",
    "```\n",
    "\n",
    "### Example\n",
    "```python\n",
    ">>> df = pd.DataFrame({\n",
    "...     'category': ['A', 'A', 'B'],\n",
    "...     'sales': [100, 200, 150]\n",
    "... })\n",
    ">>> df['pct'] = df['sales'] / df.groupby('category')['sales'].transform('sum')\n",
    ">>> df\n",
    "  category  sales   pct\n",
    "0        A    100  0.33  # 100/(100+200)\n",
    "1        A    200  0.67  # 200/(100+200)\n",
    "2        B    150  1.00  # 150/150\n",
    "```\n",
    "\n",
    "### Task\n",
    "For each row, calculate the percentage of total sales for that product. For example, if product A has sales [100, 150, 180], the percentages would be 100/430, 150/430, 180/430.\n",
    "\n",
    "Store the result in `df['pct_of_product_total']`.\n",
    "\n",
    "### Expected Properties\n",
    "- DataFrame should have a 'pct_of_product_total' column\n",
    "- For each product, the sum of percentages should equal 1.0\n",
    "- All values should be between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution:\n",
    "df = pd.DataFrame({\n",
    "    'product': ['A', 'B', 'A', 'B', 'A'],\n",
    "    'sales': [100, 200, 150, 250, 180]\n",
    "})\n",
    "\n",
    "df['pct_of_product_total'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Verification\nverify.p20(df)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "Run this cell to see your overall progress on this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}