{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas - Part 3: Data Cleaning\n",
    "\n",
    "This notebook covers handling missing data, duplicates, and type conversions.\n",
    "\n",
    "**Topics covered:**\n",
    "- Detecting missing values (isnull, notnull)\n",
    "- Handling missing data (fillna, dropna)\n",
    "- Removing duplicates\n",
    "- Type conversions (astype)\n",
    "- String operations\n",
    "\n",
    "**Problems:** 15 (Easy: 1-5, Medium: 6-10, Hard: 11-15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# SETUP - Run this cell first!\n",
    "# ============================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "from utils.checker import check\n",
    "\n",
    "# Sample data with missing values\n",
    "df = pd.DataFrame({\n",
    "    'name': ['Alice', 'Bob', None, 'David', 'Eve'],\n",
    "    'age': [25, np.nan, 35, 28, np.nan],\n",
    "    'salary': [50000, 60000, np.nan, 55000, 45000],\n",
    "    'dept': ['IT', 'HR', 'IT', None, 'HR']\n",
    "})\n",
    "print(df)\n",
    "print(\"\\nSetup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Problem 1: Check for Missing Values\n",
    "**Difficulty:** Easy\n",
    "\n",
    "### Concept\n",
    "Missing values (NaN, None, NaT) are common in real datasets. The `isnull()` method creates a boolean DataFrame showing which values are missing.\n",
    "\n",
    "### Syntax\n",
    "```python\n",
    "df.isnull()   # Returns boolean DataFrame\n",
    "df.notnull()  # Opposite of isnull()\n",
    "```\n",
    "\n",
    "### Example\n",
    "```python\n",
    ">>> df.isnull()\n",
    "    name    age  salary\n",
    "0  False  False   False\n",
    "1  False   True   False\n",
    "```\n",
    "\n",
    "### Task\n",
    "Create a boolean DataFrame showing which values are missing in `df`. Use `isnull()`. Store in `missing_mask`.\n",
    "\n",
    "### Expected Properties\n",
    "- Should be a pandas DataFrame\n",
    "- Should have same shape as df\n",
    "- Element at row 2, 'name' column should be True (missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution:\n",
    "missing_mask = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification\n",
    "check.is_type(missing_mask, pd.DataFrame, \"P1: Type check\")\n",
    "check.has_shape(missing_mask, df.shape, \"P1: Shape\")\n",
    "check.is_true(missing_mask.iloc[2]['name'] == True, \"P1: Name missing at row 2\", \"Row 2 name should be missing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Problem 2: Count Missing Values per Column\n",
    "**Difficulty:** Easy\n",
    "\n",
    "### Concept\n",
    "To get a summary of missing data, combine `isnull()` with `sum()`. Since True=1 and False=0, summing gives the count.\n",
    "\n",
    "### Syntax\n",
    "```python\n",
    "df.isnull().sum()  # Sum along rows (axis=0)\n",
    "```\n",
    "\n",
    "### Example\n",
    "```python\n",
    ">>> df.isnull().sum()\n",
    "name      1\n",
    "age       2\n",
    "salary    0\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "### Task\n",
    "Count the number of missing values in each column of `df`. Store in `missing_counts`.\n",
    "\n",
    "### Expected Properties\n",
    "- Should be a pandas Series\n",
    "- 'age' column should have 2 missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution:\n",
    "missing_counts = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification\n",
    "check.is_type(missing_counts, pd.Series, \"P2: Type check\")\n",
    "check.is_true(missing_counts['age'] == 2, \"P2: Age missing count\", \"Age should have 2 missing values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Problem 3: Drop Rows with Any Missing Values\n",
    "**Difficulty:** Easy\n",
    "\n",
    "### Concept\n",
    "`dropna()` removes rows (or columns) containing missing values. By default, it drops any row with at least one NaN.\n",
    "\n",
    "### Syntax\n",
    "```python\n",
    "df.dropna()           # Drop rows with any NaN\n",
    "df.dropna(axis=1)     # Drop columns with any NaN\n",
    "df.dropna(how='all')  # Drop only if all values are NaN\n",
    "```\n",
    "\n",
    "### Example\n",
    "```python\n",
    ">>> clean_df = df.dropna()\n",
    ">>> len(clean_df)  # Fewer rows than original\n",
    "```\n",
    "\n",
    "### Task\n",
    "Drop all rows that have any missing values from `df`. Store in `df_clean`.\n",
    "\n",
    "### Expected Properties\n",
    "- Should be a pandas DataFrame\n",
    "- Should have 2 rows (only complete rows)\n",
    "- Should have no missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution:\n",
    "df_clean = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification\n",
    "check.is_type(df_clean, pd.DataFrame, \"P3: Type check\")\n",
    "check.has_length(df_clean, 2, \"P3: Length\")\n",
    "check.has_no_nulls(df_clean, \"P3: No nulls\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Problem 4: Fill Missing Values with a Constant\n",
    "**Difficulty:** Easy\n",
    "\n",
    "### Concept\n",
    "`fillna()` replaces missing values with a specified value. This is useful when you want to use a default value instead of removing data.\n",
    "\n",
    "### Syntax\n",
    "```python\n",
    "df['column'].fillna(value)\n",
    "df.fillna(value)  # Fill all columns\n",
    "```\n",
    "\n",
    "### Example\n",
    "```python\n",
    ">>> df['age'].fillna(0)\n",
    "0    25.0\n",
    "1     0.0  # Was NaN\n",
    "2    35.0\n",
    "```\n",
    "\n",
    "### Task\n",
    "Fill all missing values in `df['age']` with 0. Store in `age_filled`.\n",
    "\n",
    "### Expected Properties\n",
    "- Should be a pandas Series\n",
    "- Should have no null values\n",
    "- Index 1 should be 0 (was NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution:\n",
    "age_filled = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification\n",
    "check.is_type(age_filled, pd.Series, \"P4: Type check\")\n",
    "check.has_no_nulls(age_filled, \"P4: No nulls\")\n",
    "check.is_true(age_filled.iloc[1] == 0, \"P4: Filled with 0\", \"Index 1 should be 0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Problem 5: Convert Data Type\n",
    "**Difficulty:** Easy\n",
    "\n",
    "### Concept\n",
    "The `astype()` method converts a Series or DataFrame column to a different data type. This is necessary after filling NaN values in numeric columns.\n",
    "\n",
    "### Syntax\n",
    "```python\n",
    "df['column'].astype(dtype)\n",
    "# Common dtypes: int, float, str, 'int64', 'float64', 'object'\n",
    "```\n",
    "\n",
    "### Example\n",
    "```python\n",
    ">>> df['age'].astype(int)\n",
    "```\n",
    "\n",
    "### Task\n",
    "Convert `age_filled` to integer type. Store in `age_int`.\n",
    "\n",
    "### Expected Properties\n",
    "- Should be a pandas Series\n",
    "- dtype should be int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution:\n",
    "age_int = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification\n",
    "check.is_type(age_int, pd.Series, \"P5: Type check\")\n",
    "check.has_dtype(age_int, np.int64, \"P5: Dtype\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Problem 6: Fill Missing with Mean\n",
    "**Difficulty:** Medium\n",
    "\n",
    "### Concept\n",
    "A common strategy for numeric columns is filling missing values with the mean (or median). This preserves the overall distribution better than using 0.\n",
    "\n",
    "### Syntax\n",
    "```python\n",
    "df['column'].fillna(df['column'].mean())\n",
    "```\n",
    "\n",
    "### Example\n",
    "```python\n",
    ">>> mean_salary = df['salary'].mean()\n",
    ">>> df['salary'].fillna(mean_salary)\n",
    "```\n",
    "\n",
    "### Task\n",
    "Fill missing values in `df['salary']` with the column's mean. Store in `salary_filled`.\n",
    "\n",
    "### Expected Properties\n",
    "- Should be a pandas Series\n",
    "- Should have no null values\n",
    "- Value at index 2 should be approximately 52500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution:\n",
    "salary_filled = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification\n",
    "check.is_type(salary_filled, pd.Series, \"P6: Type check\")\n",
    "check.has_no_nulls(salary_filled, \"P6: No nulls\")\n",
    "check.is_true(abs(salary_filled.iloc[2] - 52500.0) < 1, \"P6: Mean value\", \"Should be filled with mean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Problem 7: Drop Columns with Missing Values\n",
    "**Difficulty:** Medium\n",
    "\n",
    "### Concept\n",
    "Sometimes it's better to remove columns with too many missing values rather than trying to fill them. Use `axis=1` to drop columns instead of rows.\n",
    "\n",
    "### Syntax\n",
    "```python\n",
    "df.dropna(axis=1)         # Drop columns with any NaN\n",
    "df.dropna(axis=1, how='all')  # Drop only if all values NaN\n",
    "```\n",
    "\n",
    "### Example\n",
    "```python\n",
    ">>> df.dropna(axis=1)  # Removes columns with missing data\n",
    "```\n",
    "\n",
    "### Task\n",
    "Drop all columns that have any missing values from `df`. Store in `df_cols_clean`.\n",
    "\n",
    "### Expected Properties\n",
    "- Should be a pandas DataFrame\n",
    "- Should have 0 columns (all columns in df have missing values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution:\n",
    "df_cols_clean = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification\n",
    "check.is_type(df_cols_clean, pd.DataFrame, \"P7: Type check\")\n",
    "check.is_true(len(df_cols_clean.columns) == 0, \"P7: No columns\", \"All columns have missing values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Problem 8: Detect Duplicates\n",
    "**Difficulty:** Medium\n",
    "\n",
    "### Concept\n",
    "The `duplicated()` method returns a boolean Series indicating duplicate rows. By default, it marks all duplicates except the first occurrence.\n",
    "\n",
    "### Syntax\n",
    "```python\n",
    "df.duplicated()              # Mark duplicates (keep first)\n",
    "df.duplicated(keep='last')   # Keep last occurrence\n",
    "df.duplicated(keep=False)    # Mark all duplicates\n",
    "```\n",
    "\n",
    "### Example\n",
    "```python\n",
    ">>> df.duplicated()\n",
    "0    False\n",
    "1    False\n",
    "2     True  # Duplicate of row 1\n",
    "```\n",
    "\n",
    "### Task\n",
    "The setup code creates `df_dup` with duplicate rows. Use `duplicated()` to get a boolean Series showing duplicates. Store in `is_dup`.\n",
    "\n",
    "### Expected Properties\n",
    "- Should be a pandas Series\n",
    "- Should have 1 True value (one duplicate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup for this problem\n",
    "df_dup = pd.DataFrame({\n",
    "    'A': [1, 2, 2, 3],\n",
    "    'B': ['a', 'b', 'b', 'c']\n",
    "})\n",
    "\n",
    "# Your solution:\n",
    "is_dup = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification\n",
    "check.is_type(is_dup, pd.Series, \"P8: Type check\")\n",
    "check.is_true(is_dup.sum() == 1, \"P8: One duplicate\", \"Should have 1 duplicate row\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Problem 9: Remove Duplicates\n",
    "**Difficulty:** Medium\n",
    "\n",
    "### Concept\n",
    "`drop_duplicates()` removes duplicate rows from a DataFrame, keeping only the first (or last) occurrence.\n",
    "\n",
    "### Syntax\n",
    "```python\n",
    "df.drop_duplicates()              # Keep first occurrence\n",
    "df.drop_duplicates(keep='last')   # Keep last occurrence\n",
    "df.drop_duplicates(subset=['col']) # Check duplicates in specific columns\n",
    "```\n",
    "\n",
    "### Example\n",
    "```python\n",
    ">>> df.drop_duplicates()\n",
    "```\n",
    "\n",
    "### Task\n",
    "Remove duplicate rows from `df_dup`. Store in `df_no_dup`.\n",
    "\n",
    "### Expected Properties\n",
    "- Should be a pandas DataFrame\n",
    "- Should have 3 rows (one duplicate removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution:\n",
    "df_no_dup = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification\n",
    "check.is_type(df_no_dup, pd.DataFrame, \"P9: Type check\")\n",
    "check.has_length(df_no_dup, 3, \"P9: Length\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Problem 10: String Operations - Upper Case\n",
    "**Difficulty:** Medium\n",
    "\n",
    "### Concept\n",
    "Pandas provides string methods through the `.str` accessor. These methods automatically handle NaN values, unlike regular Python string methods.\n",
    "\n",
    "### Syntax\n",
    "```python\n",
    "df['column'].str.upper()    # Convert to uppercase\n",
    "df['column'].str.lower()    # Convert to lowercase\n",
    "df['column'].str.strip()    # Remove whitespace\n",
    "df['column'].str.contains('pattern')  # Check for pattern\n",
    "```\n",
    "\n",
    "### Example\n",
    "```python\n",
    ">>> df['name'].str.upper()\n",
    "0    ALICE\n",
    "1      BOB\n",
    "2     None\n",
    "```\n",
    "\n",
    "### Task\n",
    "Convert all values in `df['dept']` to uppercase (NaN values will remain NaN). Store in `dept_upper`.\n",
    "\n",
    "### Expected Properties\n",
    "- Should be a pandas Series\n",
    "- First element should be 'IT' (already uppercase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution:\n",
    "dept_upper = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification\n",
    "check.is_type(dept_upper, pd.Series, \"P10: Type check\")\n",
    "check.is_true(dept_upper.iloc[0] == 'IT', \"P10: First element\", \"First element should be 'IT'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Problem 11: Forward Fill Missing Values\n",
    "**Difficulty:** Hard\n",
    "\n",
    "### Concept\n",
    "Forward fill (ffill) propagates the last valid observation forward to fill missing values. This is useful for time series or ordered data.\n",
    "\n",
    "### Syntax\n",
    "```python\n",
    "df['column'].ffill()  # Forward fill\n",
    "df['column'].bfill()  # Backward fill\n",
    "```\n",
    "\n",
    "### Example\n",
    "```python\n",
    ">>> s = pd.Series([1, np.nan, np.nan, 4])\n",
    ">>> s.ffill()\n",
    "0    1.0\n",
    "1    1.0  # Filled from index 0\n",
    "2    1.0  # Filled from index 0\n",
    "3    4.0\n",
    "```\n",
    "\n",
    "### Task\n",
    "Use forward fill (ffill) to fill missing values in `df['age']`. Store in `age_ffill`.\n",
    "\n",
    "### Expected Properties\n",
    "- Should be a pandas Series\n",
    "- Index 1 should be 25.0 (forward filled from index 0)\n",
    "- Index 4 should be 28.0 (forward filled from index 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution:\n",
    "age_ffill = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification\n",
    "check.is_type(age_ffill, pd.Series, \"P11: Type check\")\n",
    "check.is_true(age_ffill.iloc[1] == 25.0, \"P11: Index 1\", \"Should be forward filled to 25.0\")\n",
    "check.is_true(age_ffill.iloc[4] == 28.0, \"P11: Index 4\", \"Should be forward filled to 28.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Problem 12: Replace Values\n",
    "**Difficulty:** Hard\n",
    "\n",
    "### Concept\n",
    "The `replace()` method substitutes specific values with new ones. This is useful for correcting data or standardizing categories.\n",
    "\n",
    "### Syntax\n",
    "```python\n",
    "df['column'].replace(old_value, new_value)\n",
    "df['column'].replace([val1, val2], [new1, new2])  # Multiple replacements\n",
    "df['column'].replace({'old1': 'new1', 'old2': 'new2'})  # Dict mapping\n",
    "```\n",
    "\n",
    "### Example\n",
    "```python\n",
    ">>> df['status'].replace('active', 'ACTIVE')\n",
    "```\n",
    "\n",
    "### Task\n",
    "In `df['dept']`, replace 'IT' with 'Technology'. Store in `dept_replaced`.\n",
    "\n",
    "### Expected Properties\n",
    "- Should be a pandas Series\n",
    "- Index 0 should be 'Technology' (was 'IT')\n",
    "- Index 2 should be 'Technology' (was 'IT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution:\n",
    "dept_replaced = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification\n",
    "check.is_type(dept_replaced, pd.Series, \"P12: Type check\")\n",
    "check.is_true(dept_replaced.iloc[0] == 'Technology', \"P12: Index 0\", \"Should be 'Technology'\")\n",
    "check.is_true(dept_replaced.iloc[2] == 'Technology', \"P12: Index 2\", \"Should be 'Technology'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Problem 13: Drop Rows with Threshold\n",
    "**Difficulty:** Hard\n",
    "\n",
    "### Concept\n",
    "The `thresh` parameter in `dropna()` specifies the minimum number of non-null values required to keep a row. This is more flexible than dropping any row with missing data.\n",
    "\n",
    "### Syntax\n",
    "```python\n",
    "df.dropna(thresh=n)  # Keep rows with at least n non-null values\n",
    "```\n",
    "\n",
    "### Example\n",
    "```python\n",
    ">>> # Keep rows with at least 3 non-null values\n",
    ">>> df.dropna(thresh=3)\n",
    "```\n",
    "\n",
    "### Task\n",
    "Drop rows that have less than 3 non-null values from `df`. Use `thresh` parameter. Store in `df_thresh`.\n",
    "\n",
    "### Expected Properties\n",
    "- Should be a pandas DataFrame\n",
    "- Should have 4 rows (one row dropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution:\n",
    "df_thresh = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification\n",
    "check.is_type(df_thresh, pd.DataFrame, \"P13: Type check\")\n",
    "check.has_length(df_thresh, 4, \"P13: Length\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Problem 14: Fill Different Values per Column\n",
    "**Difficulty:** Hard\n",
    "\n",
    "### Concept\n",
    "You can fill different columns with different values by passing a dictionary to `fillna()`. This allows column-specific filling strategies.\n",
    "\n",
    "### Syntax\n",
    "```python\n",
    "df.fillna({'col1': value1, 'col2': value2})\n",
    "```\n",
    "\n",
    "### Example\n",
    "```python\n",
    ">>> df.fillna({\n",
    "...     'age': 0,\n",
    "...     'name': 'Unknown',\n",
    "...     'salary': df['salary'].median()\n",
    "... })\n",
    "```\n",
    "\n",
    "### Task\n",
    "Fill missing values in df with different values per column:\n",
    "- 'age' with 0\n",
    "- 'salary' with median\n",
    "- 'name' with 'Unknown'\n",
    "- 'dept' with 'Other'\n",
    "\n",
    "Store in `df_filled`.\n",
    "\n",
    "### Expected Properties\n",
    "- Should be a pandas DataFrame\n",
    "- Should have no null values\n",
    "- Index 2 name should be 'Unknown'\n",
    "- Index 3 dept should be 'Other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution:\n",
    "df_filled = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification\n",
    "check.is_type(df_filled, pd.DataFrame, \"P14: Type check\")\n",
    "check.has_no_nulls(df_filled, \"P14: No nulls\")\n",
    "check.is_true(df_filled['name'].iloc[2] == 'Unknown', \"P14: Name filled\", \"Should be 'Unknown'\")\n",
    "check.is_true(df_filled['dept'].iloc[3] == 'Other', \"P14: Dept filled\", \"Should be 'Other'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Problem 15: Interpolate Missing Values\n",
    "**Difficulty:** Hard\n",
    "\n",
    "### Concept\n",
    "Interpolation fills missing values by estimating them based on surrounding values. Linear interpolation creates a straight line between known points.\n",
    "\n",
    "### Syntax\n",
    "```python\n",
    "df['column'].interpolate()           # Linear by default\n",
    "df['column'].interpolate(method='polynomial', order=2)  # Other methods\n",
    "```\n",
    "\n",
    "### Example\n",
    "```python\n",
    ">>> s = pd.Series([1, np.nan, np.nan, 4])\n",
    ">>> s.interpolate()\n",
    "0    1.0\n",
    "1    2.0  # Interpolated\n",
    "2    3.0  # Interpolated\n",
    "3    4.0\n",
    "```\n",
    "\n",
    "### Task\n",
    "The setup creates a Series `s` with missing values. Use linear interpolation to fill them. Store in `s_interp`.\n",
    "\n",
    "### Expected Properties\n",
    "- Should be a pandas Series\n",
    "- Index 1 should be approximately 2.0\n",
    "- Index 2 should be approximately 3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "s = pd.Series([1, np.nan, np.nan, 4, 5])\n",
    "\n",
    "# Your solution:\n",
    "s_interp = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification\n",
    "check.is_type(s_interp, pd.Series, \"P15: Type check\")\n",
    "check.is_true(abs(s_interp.iloc[1] - 2.0) < 0.1, \"P15: Index 1\", \"Should be approximately 2.0\")\n",
    "check.is_true(abs(s_interp.iloc[2] - 3.0) < 0.1, \"P15: Index 2\", \"Should be approximately 3.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "Run this cell to see your overall progress on this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
